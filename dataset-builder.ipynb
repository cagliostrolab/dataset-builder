{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d3155f-6a89-4de4-b613-3d8e40b5b8d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|██████████| 12737/12737 [00:07<00:00, 1667.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import threading\n",
    "import shutil\n",
    "import dateutil.parser\n",
    "from queue import Queue\n",
    "from tqdm import tqdm\n",
    "\n",
    "total_files = 0\n",
    "downloaded_files = 0\n",
    "download_lock = threading.Lock()\n",
    "\n",
    "def download_image(folder, url, filename, extension):\n",
    "    global downloaded_files\n",
    "    full_path = f\"{folder}/{filename}.{extension}\"\n",
    "    if os.path.exists(full_path):\n",
    "        return False\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            with open(full_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            with download_lock:\n",
    "                downloaded_files += 1\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        return False\n",
    "        \n",
    "def write_metadata(folder, filename, tags):\n",
    "    with open(f\"{folder}/{filename}.txt\", \"w\") as f:\n",
    "        f.write(tags)\n",
    "    \n",
    "def generate_tags(data):\n",
    "    def process_tags(tag_str):\n",
    "        processed_tags = []\n",
    "        for tag_name in tag_str.split(\" \"):\n",
    "            if len(tag_name) > 3:\n",
    "                tag_name = tag_name.replace(\"_\", \" \")\n",
    "            processed_tags.append(tag_name)\n",
    "        return \", \".join(processed_tags)\n",
    "\n",
    "    created_at = data.get(\"media_asset\", {}).get(\"created_at\", \"\")\n",
    "    try:\n",
    "        parsed_date = dateutil.parser.isoparse(created_at)\n",
    "        year = parsed_date.year\n",
    "        if 2005 <= year <= 2010:\n",
    "            year_tag = \"oldest\"\n",
    "        elif 2011 <= year <= 2014:\n",
    "            year_tag = \"early\"\n",
    "        elif 2015 <= year <= 2018:\n",
    "            year_tag = \"mid\"\n",
    "        elif 2019 <= year <= 2021:\n",
    "            year_tag = \"late\"\n",
    "        elif 2022 <= year <= 2023:\n",
    "            year_tag = \"newest\"\n",
    "        else:\n",
    "            year_tag = \"unknown\"\n",
    "    except (ValueError, AttributeError):\n",
    "        print(\"Invalid or missing created_at date.\")\n",
    "        year_tag = \"unknown\"\n",
    "\n",
    "    rating = data.get(\"rating\")\n",
    "    score = data.get(\"score\")\n",
    "\n",
    "    tags_general = process_tags(data.get(\"tag_string_general\", \"\"))\n",
    "    tags_character = process_tags(data.get(\"tag_string_character\", \"\"))\n",
    "    tags_copyright = process_tags(data.get(\"tag_string_copyright\", \"\"))\n",
    "    tags_artist =  process_tags(data.get(\"tag_string_artist\", \"\"))\n",
    "    tags_meta =  process_tags(data.get(\"tag_string_meta\", \"\"))\n",
    "    \n",
    "    quality_tag = \"\"\n",
    "    if score > 150:\n",
    "        quality_tag = \"masterpiece, \"\n",
    "    elif 100 <= score <= 150:\n",
    "        quality_tag = \"best quality\"\n",
    "    elif 75 <= score < 100:\n",
    "        quality_tag = \"high quality\"\n",
    "    elif 25 <= score < 75:\n",
    "        quality_tag = \"medium quality\"\n",
    "    elif 0 <= score < 25 :\n",
    "        quality_tag = \"normal quality\"\n",
    "    elif -5 <= score < 0:\n",
    "        quality_tag = \"low quality\"\n",
    "    elif score < -5:\n",
    "        quality_tag = \"worst quality\"\n",
    "\n",
    "    if rating in \"q\":\n",
    "        nsfw_tags = \"rating: questionable, nsfw\"\n",
    "    elif rating in \"e\":\n",
    "        nsfw_tags = \"rating: explicit, nsfw\"\n",
    "    elif rating in \"s\":\n",
    "        nsfw_tags = \"rating: sensitive\"\n",
    "    else:\n",
    "        nsfw_tags = \"rating: general\"\n",
    "\n",
    "    tags_general_list = tags_general.split(', ')\n",
    "    special_tags = [\n",
    "        \"1girl\", \"2girls\", \"3girls\", \"4girls\", \"5girls\", \"6+girls\", \"multiple girls\",\n",
    "        \"1boy\", \"2boys\", \"3boys\", \"4boys\", \"5boys\", \"6+boys\", \"multiple boys\", \"male focus\"\n",
    "    ]\n",
    "\n",
    "    found_special_tags = [tag for tag in tags_general_list if tag in special_tags]\n",
    "\n",
    "    for tag in found_special_tags:\n",
    "        tags_general_list.remove(tag)\n",
    "\n",
    "    first_general_tag = ', '.join(found_special_tags)\n",
    "    rest_general_tags = ', '.join(tags_general_list)\n",
    "\n",
    "    tags_separator = \"|||\"\n",
    "    \n",
    "    pre_separator_tags = []\n",
    "    post_separator_tags = []\n",
    "\n",
    "    if first_general_tag:\n",
    "        pre_separator_tags.append(first_general_tag)\n",
    "    if tags_character:\n",
    "        pre_separator_tags.append(tags_character)\n",
    "    if tags_copyright:\n",
    "        pre_separator_tags.append(tags_copyright)\n",
    "    if tags_artist:\n",
    "        pre_separator_tags.append(tags_artist)\n",
    "\n",
    "    if nsfw_tags:\n",
    "        post_separator_tags.append(nsfw_tags)\n",
    "    if rest_general_tags:\n",
    "        post_separator_tags.append(rest_general_tags)\n",
    "    if year_tag:\n",
    "        post_separator_tags.append(year_tag)\n",
    "    if tags_meta:\n",
    "        post_separator_tags.append(tags_meta)\n",
    "    if quality_tag:\n",
    "        post_separator_tags.append(quality_tag)\n",
    "\n",
    "    pre_separator_str = ', '.join(pre_separator_tags)\n",
    "    post_separator_str = ', '.join(post_separator_tags)\n",
    "\n",
    "    caption = f\"{pre_separator_str}, {tags_separator} {post_separator_str}\"\n",
    "    \n",
    "    print(caption)\n",
    "    print()\n",
    "    return caption\n",
    "\n",
    "def process_file(json_folder, json_file):\n",
    "    with open(f\"{json_folder}/{json_file}\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    extension = data.get(\"file_ext\")\n",
    "    rating_map = {'g': 'general', 's': 'sensitive', 'q': 'questionable', 'e': 'explicit'}\n",
    "    rating = rating_map.get(data.get(\"rating\"), \"\")\n",
    "    file_url = data.get(\"file_url\")\n",
    "\n",
    "    if extension not in [\"png\", \"jpg\", \"jpeg\", \"webp\", \"bmp\"]:\n",
    "        return\n",
    "\n",
    "    tags = generate_tags(data)\n",
    "    \n",
    "    if download_image(rating, file_url, json_file.split(\".\")[0], extension):\n",
    "        processed_folder = f\"{json_folder}_processed\"\n",
    "        os.makedirs(processed_folder, exist_ok=True)\n",
    "        shutil.move(f\"{json_folder}/{json_file}\", f\"{processed_folder}/{json_file}\")\n",
    "        \n",
    "    write_metadata(rating, json_file.split(\".\")[0], tags)\n",
    "\n",
    "def worker(queue, json_folder, pbar):\n",
    "    while True:\n",
    "        json_file = queue.get()\n",
    "        if json_file is None:\n",
    "            break  # Exit signal\n",
    "        process_file(json_folder, json_file)\n",
    "        queue.task_done()\n",
    "        pbar.update(1)  # Update progress bar\n",
    "\n",
    "def main(json_folder):\n",
    "    global total_files\n",
    "    total_files = len(os.listdir(json_folder))\n",
    "\n",
    "    rating_folders = ['general', 'sensitive', 'questionable', 'explicit']\n",
    "\n",
    "    for folder in rating_folders:\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "\n",
    "    queue = Queue()\n",
    "    threads = []\n",
    "    num_worker_threads = 4\n",
    "\n",
    "    with tqdm(total=total_files, desc=\"Processing Files\") as pbar:\n",
    "        for _ in range(num_worker_threads):\n",
    "            t = threading.Thread(target=worker, args=(queue, json_folder, pbar))\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "\n",
    "        for json_file in os.listdir(json_folder):\n",
    "            queue.put(json_file)\n",
    "\n",
    "        queue.join()\n",
    "\n",
    "        for _ in range(num_worker_threads):\n",
    "            queue.put(None)\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "    print(\"Scraping complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    project_path = \"/workspace/train_data/animagine-xl-3.0\"\n",
    "    os.makedirs(project_path, exist_ok=True)\n",
    "    os.chdir(project_path)\n",
    "    main(\"/workspace/animagine-v3-json-curated\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
