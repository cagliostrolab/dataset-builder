{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8bda99-dd1b-4899-9162-4c5d2d427b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hf_transfer transformers -q\n",
    "!export HF_HUB_ENABLE_HF_TRANSFER=True\n",
    "!huggingface-cli download shadowlilac/aesthetic-shadow-v2 model.safetensors --local-dir /workspace/aesthetic_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4653e3-6fa4-4e82-8ae9-873b9ee672ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "import safetensors.torch\n",
    "from transformers import pipeline, AutoConfig, AutoProcessor, ViTForImageClassification\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "base_directory = \"/workspace/train_data/animagine-xl-3.1\"\n",
    "model_path = '/workspace/aesthetic_scorer/model.safetensors'\n",
    "batch_size = 64  \n",
    "extensions = ('png', 'jpg', 'jpeg', 'webp')\n",
    "num_workers = 8 \n",
    "aesthetic_tags = ['very aesthetic', 'aesthetic', 'displeasing', 'very displeasing']  \n",
    "\n",
    "class ShadowScore:\n",
    "    def __init__(self, pathname, device, high_quality_label='hq'):\n",
    "        self.pipe = None\n",
    "        self.device = device\n",
    "        self.pathname = pathname\n",
    "        self.high_quality_label = high_quality_label\n",
    "        self.initialize_model()\n",
    "\n",
    "    def initialize_model(self):\n",
    "        print(\"Loading model...\")\n",
    "        statedict = safetensors.torch.load_file(self.pathname)\n",
    "        config = AutoConfig.from_pretrained(\"shadowlilac/aesthetic-shadow-v2\")\n",
    "        model = ViTForImageClassification.from_pretrained(pretrained_model_name_or_path=None, state_dict=statedict, config=config)\n",
    "        processor = AutoProcessor.from_pretrained(\"shadowlilac/aesthetic-shadow-v2\")\n",
    "        device_str = str(self.device).replace('cuda:0', 'cuda')\n",
    "        self.pipe = pipeline(\"image-classification\", model=model, image_processor=processor, device=device_str)\n",
    "        print(\"Model loaded.\")\n",
    "\n",
    "    def score(self, images):\n",
    "        scores = self.pipe(images=images)\n",
    "        results = []\n",
    "        for score in scores:\n",
    "            value = [p for p in score if p['label'] == self.high_quality_label][0]['score']\n",
    "            if value > 0.71:\n",
    "                tag = 'very aesthetic'\n",
    "            elif value > 0.45 and value < 0.71:  # Corrected syntax\n",
    "                tag = 'aesthetic'\n",
    "            elif value > 0.27 and value < 0.45:  # Corrected syntax\n",
    "                tag = 'displeasing'\n",
    "            else:\n",
    "                tag = 'very displeasing'\n",
    "            results.append((value, tag))\n",
    "        return results\n",
    "\n",
    "def find_images(base_path, extensions):\n",
    "    valid_images = []\n",
    "    for root, _, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(extensions):\n",
    "                valid_images.append(os.path.join(root, file))\n",
    "    return valid_images\n",
    "\n",
    "def load_image(path):\n",
    "    with Image.open(path) as img:\n",
    "        return img.copy()\n",
    "\n",
    "def load_images_parallel(image_paths):\n",
    "    images = [None] * len(image_paths)\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        future_to_index = {executor.submit(load_image, path): i for i, path in enumerate(image_paths)}\n",
    "        for future in as_completed(future_to_index):\n",
    "            index = future_to_index[future]\n",
    "            images[index] = future.result()\n",
    "    return images\n",
    "\n",
    "def has_aesthetic_tags(image_path, aesthetic_tags):\n",
    "    txt_path = os.path.splitext(image_path)[0] + '.txt'\n",
    "    if os.path.exists(txt_path):\n",
    "        with open(txt_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            for tag in aesthetic_tags:\n",
    "                if tag in content:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def resize_and_display_image(image_path, base_width=256):\n",
    "    with Image.open(image_path) as img:\n",
    "        w_percent = (base_width / float(img.size[0]))\n",
    "        h_size = int((float(img.size[1]) * float(w_percent)))\n",
    "        img = img.resize((base_width, h_size), Image.LANCZOS)\n",
    "        img.show()\n",
    "        \n",
    "def append_tag_to_text_file(image_path, tag):\n",
    "    txt_path = os.path.splitext(image_path)[0] + '.txt'\n",
    "    if os.path.exists(txt_path):\n",
    "        with open(txt_path, 'r+', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            if tag not in content:\n",
    "                if content.strip():  # If file is not empty, prepend a comma\n",
    "                    content += ', '\n",
    "                content += tag\n",
    "                print(content)\n",
    "                file.seek(0)\n",
    "                file.write(content)\n",
    "                file.truncate()\n",
    "            \n",
    "    else:\n",
    "        with open(txt_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(tag)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "shadow_score = ShadowScore(pathname=model_path, device=device)\n",
    "\n",
    "all_image_paths = find_images(base_directory, extensions)\n",
    "total_images = len(all_image_paths)\n",
    "\n",
    "for i in tqdm(range(0, total_images, batch_size), desc=\"Processing batches\"):\n",
    "    batch_paths = all_image_paths[i:i+batch_size]\n",
    "    batch_images = []\n",
    "    batch_paths_to_process = []\n",
    "\n",
    "    for path in batch_paths:\n",
    "        if not has_aesthetic_tags(path, aesthetic_tags):\n",
    "            image = load_image(path)\n",
    "            if image is not None:  # Only append if the image was successfully loaded\n",
    "                batch_paths_to_process.append(path)\n",
    "                batch_images.append(image)\n",
    "\n",
    "    if not batch_images:  \n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        batch_scores = shadow_score.score(batch_images)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch starting with image path: {batch_paths_to_process[0]}\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        continue  \n",
    "\n",
    "    for path, (score, tag) in zip(batch_paths_to_process, batch_scores):\n",
    "        # print(f\"Image: {path}, Score: {score:.2f}, Tag: {tag}\")\n",
    "        append_tag_to_text_file(path, tag)\n",
    "        # resize_and_display_image(path, base_width=512)\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
